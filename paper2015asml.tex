%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{wrapfig}
\usepackage{graphicx,color}

\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{cases}
\usepackage{xspace}
%\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{array}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

%EDITING COMMANDS
\newcommand{\hilight}[1]{\colorbox{red}{#1}}
\newcommand{\todo}{\colorbox{red}{TODO}}
\newcommand{\tj}[1]{\ensuremath{\xi_\text{#1}}}

\title{\LARGE \bf
Towards a Data-driven Approach to Motion Planning
}


\author{Arjun Menon$^{1}$, Sachin Chitta$^{1}$, Mark Moll$^{2}$, Lydia Kavraki$^{2}$% <-this % stops a space
\thanks{*This work was supported by ...}% <-this % stops a space
\thanks{$^{1}$SRI International, Menlo Park, CA
        {\tt\small arjun.menon@sri.com, sachin.chitta@sri.com}}%
\thanks{$^{2}$Rice University, Department of Computer Science, Houston, TX
        {\tt\small mmoll@rice.edu, kavraki@rice.edu}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Co-robots, i.e. robots that need to work close to people, will need to account for the preferences and expectations of their human 
co-workers in executing motions or actions. Consistent, legible and predictable motions are a key factor in making humans comfortable 
around robots. In this work, we take a first step towards designing motions that are more acceptable to human co-workers by asking 
people to rate robot motions generated in a variety of environments. Our approach is data-driven, i.e. we aim to use data from an online 
survey to inform good quality paths and trajectories. We compute a set of features for each trajectory and use the features 
and associated ratings to try add predict a quality score that represents how well the human observers liked the trajectory. We present an 
analysis of the dataset that we have collected, highlighting the features that dominate the trajectories that people prefer. We also 
present a classifier that will return the quality score for a given trajectory. Finally, we discuss how a data-driven approach using the 
results of this analysis can be used to help design better plans that are more acceptable to people. 
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Robots working in industrial environments have traditionally been limited to simple, efficient point to point motions. Robotic workcells 
typically require a safety cage to prevent people from being getting close. Robotic motion generation, therefore, does not take 
into account any notion of the acceptability of motions for human observers. The need for more flexibility in manufacturing and logistics, 
though, has resulted in a greater need for robots that can work beside humans. As robots and people start becoming co-workers, taking 
human perception of robotic paths into account will become more important. Humans are able to predict and adjust their motions to 
account for the expectations and motions of their co-workers easily. For human co-workers to be comfortable, robots will similarly 
have to tailor their motions for the presence and actions of the people around them. 

In this work, we take a first step towards the ultimate goal of generating robotic arm motions in cluttered environments that are acceptable for human observers and co-workers. We start with a survey where human observers rate robot motion quality. We generated a range of trajectories across multiple environments with different planners. The motion planning problems we chose required a (simulated) robot to move its arm from a specified end-effector start position to a desired end-effector goal position. Movies of these trajectories from multiple viewpoints were then presented to human observers using an online survey tool. The users were asked to rate different attributes of the trajectories. We also computed a large set of features for each trajectory. The feature set was designed to be easily extensible across different types of robots and also captures the relationship between the trajectories and the environment. We use the feature set, coupled with machine learning techniques, to build a classifier that predicts the human rating for a given trajectory. The classifiers also help in identifying a set of features that are the most important in predicting human preferences for robot trajectories. The classifiers could also form the basis for a new {\em data-driven} approach to motion planning. 

This paper is organized as follows. In Section~\ref{sec:background}, we first describe some of the existing approaches to designing better quality paths for robots. We also look at how human motion information has inspired work in designing better trajectories for robots. In Section~\ref{sec:survey}, we present details of the online survey including information about the types of trajectories and environments used. Section~\ref{sec:raw_results} presents raw results from the survey, including examples of trajectories that were rated well and badly. In Section~\ref{sec:analysis}, we present a set of features corresponding to the trajectories and use a machine learning approach to derive a classifier for predicting the rating of trajectories. In Section~\ref{sec:conclusion}, we conclude with a discussion of how our results could be used to design motion planners that generate more human-acceptable trajectories. 

\begin{figure}
\centering
  \includegraphics[trim = 70mm 0mm 70mm 0mm, width=0.62\columnwidth, clip=true]{pictures/countertop_scene2}
  \begin{minipage}[b][][s]{0.352\columnwidth}
  \centering
    \includegraphics[trim = 70mm 0mm 70mm 0mm, width=\textwidth, clip=true]{pictures/drawer_scene2}
    \vfill
    \includegraphics[trim = 30mm 0mm 30mm 0mm, width=\textwidth, clip=true]{pictures/industrial_scene2}
  \end{minipage}
\caption{The scenes used in generating the library of robot motions to collect feedeback for. \emph{Drawer} (top right), \emph{Countertop} (left), and \emph{Industrial} (bottom right)}\label{fig:scenes}
\end{figure}

\section{Background}
\label{sec:background}

\begin{table*}
\centering
\begin{tabular}{|c||c|c|c|c|c|c|c|}
\hline
Efficiency  & Highly inefficient& Moderately inefficient& Slightly inefficient& Neutral & Slightly efficient& Moderately efficient& Highly efficient\\
\hline
Elegance    & Highly awkward& Moderately awkward& Slightly awkward& Neutral & Slightly elegant& Moderately elegant& Highly elegant\\
\hline
Smoothness  & Highly rough& Moderately rough& Slightly rough& Neutral & Slightly smooth& Moderately smooth& Highly smooth\\
\hline
Overall     & Extremely poor& Moderately poor& Somewhat poor& Neutral & Somewhat good& Moderately good& Extremely good\\
\hline
\end{tabular}
\caption{The rating categories and the associated scale presented to the survey participant}
\label{tab:rating_scales}
\end{table*}

Robot motion study for industrial has been primarily influenced by the need to generate smooth jerk-free trajectories that minimize wear and tear of internal parts. In recent years, there has been more interest in the generation of motions for robots working in human environments, i.e. environments with clutter and people working next to the robots. Most attention, though, has been focused on generating {\em collision-free} motions. Examples include the use of randomized planners\cite{kuffner_RRT_icra00}, trajectory optimization techniques\cite{Mrinal:2011}, and deterministic search-based techniques\cite{Cohen:2012}. Such approaches have also been modified to account for other types of constraints, e.g. dynamic constraints or process constraints arising from the task. 

Human motions have been the subject of recent stufy with the intent of determining whether there are certain motor or locomotor invariants that best describe human manipulation or locomotion. Human motion has been observed to be stereo-typical~\cite{Atkeson:85}, i.e. learned motion patterns that are repeatedly used. This requires less planning of individual motions and contributes to making human motions more deterministic and predictable. The minimum jerk principle for human motions specifies that the trajectory of the human can best be represented as a motion that minimizes jerk of the hand~\cite{Flash:85}. Uno et. al.~\cite{Uno:89} used minimum torque change as a measure to explain the observed human motions. Minimizing jerk at the joint level~\cite{Rosenbaum:1995} has been another criterion used for human motion. Human motion has also been found to be optimized~\cite{Arechavaleta:2006}. Albrech et. al.~\cite{Albrecht:2011} studied the reaching motions of several subjects in table-setting situations and attempted to codify the motion using cost functions representing minimum-jerk hand motions, minimum-jerk joint motions, minimum torque change and a combination of all three. They found that no single combination of the cost functions explained the observed data completely. 

Recent work has also addressed the task of making motions predictable (similar motions in similar environments and tasks) and/or legible (make it easier for human observers to understand the intent of the robot)~\cite{Beetz:2010}. Legibility makes it possible for human observers to understand clearly what a robot is intending to do, allowing them to modify their actions and motions if necessary. Predictability implies that the robot will always be consistent in its actions, removing the element of surprise for human observers. These concepts have been well-studies recently with the intent of measuring legibility~\cite{Lichtenthaler:2011}, using expressions to improve the readability of robots~\cite{Takayama:2011} and generating anticipation~\cite{Gielniak:2011}. In~\cite{Dragan:2013}, the notion of legibility was incorporated into a constrained trajectory optimization motion planner to generate motions that are more legible to human observers. 

There has been relatively little examination of how human observers perceive robot arm trajectories in environments with obstacles. There is no data available for how human observers react to such robot motions. It is not clear whether minimum-jerk trajectories (or other cost functions) are the best descriptors of motions in such environments or if there are other features that better explain human-observer preferences in such sitations. Our goal in this work is to collect the data needed to answer the query, "Which robot trajectories in cluttered environments do human-observers prefer". A second question that we would like to answer is "Why are certain robot trajectories preferred by human-observers?". This is a larger question that we aim to address in future work and instead we focus on,"Can we predict a human-observer preference for a given trajectory". The answer to this latter question, we hope, will eventually point us towards a cost function for generating more human friendly motion plans. 

\section{Approach}
\label{sec:survey}
Our approach starts with an online survey designed to get information from multiple users about how well they like robot trajectories. In this section, we will describe in detail the infrastructure used to create the trajectories and movies that were used in the survey. We will also describe the online survey procedure in detail. 

\subsection{Planning System Infrastructure}

The MoveIt! benchmarking architecture~\cite{cohen2012generic} was extended with video recording capabilities to quickly generate a large number of trajectories. The MoveIt! architecture allows for the definition of environments, referred to as planning scenes, start and goal states for robots (motion planning queries). It also allows for the use of any supported planning algorithms (planners). A combination of different scenes, motion queries, and planners was used to generate robot trajectories for evalutation. We chose three distinct scenes (shown in~\ref{fig:scenes}): a kitchen ({\sc Countertop}), an industrial workbench ({\sc Industrial}) and a drawer on a table ({\sc Drawer}). Multiple queries were generated in each scene for motions of the right arm of the PR2 robot. The robot was positioned in the scenes manually and motion planning queries were constructed by hand~\ref{fig:design}. The positioning in the scenes was done with the expectation that the planning queries would not be impossible or trivial for the planning algorithms to solve. 

%\begin{figure}[b]
%    \includegraphics[trim = 0mm 0mm 0mm 0mm, width=\columnwidth]{pictures/designing_queries_moveit}
%    \caption{Screenshot of the planning query design process which involved hand-picking start and goal query poses for the various scenes manually to ensure they were neither trivial nor impossible for the planning algorithms to solve. This was accomplished through use of RVIZ and interactive markers.}
%    \label{fig:design}
%\end{figure}

The planning algorithms that we used are RRT-Connect~\cite{kuffner2000rrt} and RRT*.  RRT*~\cite{frazzoli-RRTstar} was used with two different cost functions: {\sc PathLength} and {\sc MaxMinClearance}.The objective for {\sc PathLength} minimizes the length of the trajectory (as the sum of the euclidean distances between ends of trajectory segments). The objective for {\sc MaxMinClearance} computes uses the minimum clearance of a configuration belonging to a trajectory as the value it is trying to maximize. Both planners are implemented in the OMPL library~\ref{OMPL:2012}. 

\todo formulae for optimization objectives?

The infrastructure we designed around MoveIt! allowed us to automatically generate movies of the generated trajectories using the ROS Visualizer (Rviz). We generated movies from different viewpoints to maximize the visibility of the motion to human observers reviewing it. Each participant was allowed to provide feedback no more than once for each of the trajectories generated by the survey design. We ran the survey for 103 trajectories, requesting no more than 20 ratings per trajectory. Participants are allowed to rate multiple distinct trajectories, but no more than once. The analysis of these results is presented in Section~\ref{sec:analysis}.

\subsection{Online Survey}

%\begin{figure}
%    \frame{\includegraphics[trim = 0mm 0mm 0mm 0mm, width=\columnwidth]{pictures/amazon_survey_screenshot}}
%    \caption{The main survey question which prompts the participant for a rating in four motion characteristics (efficiency, elegance, smoothness and overall impression) after presenting a video that demonstrates the motion from four clearly visible vantage points for any sample trajectory.}
%    \label{fig:survey_question}
%\end{figure}


\subsubsection{Demographic Questions}

Participants were asked a few demographic questions which ask about:

\begin{itemize}
\item Familiarity with videogames
\item Familiarity with robotics
\item The participant's age group: We asked whether the participant belonged to the 18-24, 25-44, 45-64, and 65+ age brackets.
\item The participant's highest education level: We asked if the particpant had a PhD/Masters, a Bachelors, Associate or High School level degree as their highest education.
\end{itemize}

None of these pieces of information were used to filter the responses we collected.

\todo find info on relation between videogame and robotics

\subsubsection{Survey Design and Process}

The surveys were presented to users of Amazon Mechanical Turk~\cite{paolacci2010running}, who would be presented with a set of demographic questions, a video, and the four scales to rate the robot's motion on the basis of elegance, efficency, smoothness and overall impression. Additionally a control question was presented with another video asking the participant about the robot's action in the accompanying video. This served as the first satisficing trap to ensure that participants were truthfully attempting the survey. On overview of the main survey question can be seen in Figure~\ref{fig:survey_question}.

Mechanical Turk allows dispensing of monetary compensation on completion, which was set to 15\textcent~ per survey. The expected time to complete was 1-2 minutes, which allows the participant about 1 whole minute of deliberation when assigning ratings. Additionally, the participants were allowed to replay the trajectory video repeatedly (and other features that Youtube supports). This maximum possible payout is 15.45\textdollar~ or if each survey took on average 1.5 minutes to complete about 6\textdollar~ per hour of work for a participant.

%\begin{figure}
%\frame{\includegraphics[trim = 0mm 0mm 0mm 0mm, width=\columnwidth]{pictures/amazon_control_question}}
%\caption{The survey control question which prompts the participant about the action of the robot in the accompanying video. The question we adopted was to ask the particpant which colored cube the robot touched.}
%\label{fig:control_question}
%\end{figure}

In addition to the rating and demographic questions, a control question was incorporated to account for satisficing in online surveys~\cite{krosnick1991response}~\cite{krosnick1996satisficing}. The question format can be seen in Figure~\ref{fig:control_question}. This question served as the first counter-measure against satisficing in the survey. 

The other counter-measure was to manually inspect the responses, and assess whether it agrees with the other survey respondents on a participant-by-participant and then trajectory-by-trajectory basis. The process for examining a particular participant involves seeing how his/her ratings {\em agree or disagree} with the average ratings of all the other ratings for this particular trajectory. Aggregating this over all the trajectories the participant rated gives us an idea of how much we can trust their responses and make a decision about rejecting {\em all or none} of their responses. 

Another heuristic we employed in inspecting the responses was looking for the average time to complete the survey to be extremely low, which could hint at strong satisficing.

We found that for our set of data, all the participant ratings for a given trajectory for the were usually within one standard deviation of the average rating for that trajectory. This leads us towards rejecting none of the data we received after running the survey.

\section{Survey Results}
\label{sec:analysis}
The results of the survey are summarized in Fig.~\ref{fig:survey_raw} which shows a histogram of (average) responses for each of the four survey questions across the 100 trajectories that were rated by users. It is clear that a majority of the trajectories in our survey were well received by the human observers but there were quite a few trajectories that were rated badly as well. 
\begin{figure}[t]
  \centering{\includegraphics[width=0.45\linewidth]{pictures/efficiency}}
  \centering{\includegraphics[width=0.45\linewidth]{pictures/elegant}}
  \centering{\includegraphics[width=0.45\linewidth]{pictures/smooth}}
  \centering{\includegraphics[width=0.45\linewidth]{pictures/overall}}
  \caption{Histogram of averaged ratings for the 103 different trajectories. Clockwise from top left: Efficient vs. Inefficient, Elegant vs. Inelegant, Smooth vs. Rough, Overall Rating}
\label{fig:survey_raw}
\end{figure}


An analysis of the ratings for each trajectory showed that four (averaged) ratings for each individual trajectory were always similar to each other, indicating that users had similar preferences for each trajectory regardless of the individual attributes used to describe the preference for the trajectory (efficient, elegant, smooth). 

Confidence intervals for the overall rating of each trajectory are shown in Fig.~\ref{confidence}. The small spread in the confidence intervals clearly indicates that different users had similar opinions about the same trajectory. Indeed, we found little evidence of any personal preference or clustering of users based on their preference for certain trajectories over others. 

\section{Feature Design for Trajectory Classification}

The trajectory features we selected for the classification task consider the environment, the shape of the trajectory and the dynamics-related quantities. These make up our unary features computed only on the input trajectory. 

We also include features that compare each trajectory to a nominal trajectory for its problem which also serve to characterize how much the trajectory deviates from the "expected" path. We go over the selection of the nominal path in Section~\ref{subsec:multi_traj_feat}.

\subsection{Unary Trajectory Features}

Here we detail the features we computed on the trajectory \tj{} with waypoints $q_i$ where $i={0,\mathellipsis,n}$ and $n=|\tj{}|$.

\subsubsection{Path length}

The length of the trajectory \tj{} computed as the sum over trajectory segments of the euclidean distance between end points of the segment, or

\begin{equation}
\text{Length} = \sum_{i=0}^{n-1} \| q_\text{i}-q_\text{i+1} \|
\end{equation}

We compute Path Length for the joint space trajectory and for three workspace trajectories that are dervied from the forward kinematic map of the joint-space trajectory for the following links in the kinematic chain: for the elbow ($\xi_\text{elbow}$), wrist ($\xi_\text{wrist}$) and finger-tip ($\xi_\text{tip}$).

\subsubsection{Clearance}

The average clearance of a trajectory \tj{} is the average minimum distance of configurations at waypoints to the closest obstacle, or

\begin{equation}
\text{Clearance} = \frac{1}{n} \sum_{i=0}^n \min_{o \in O} \text{dist}(q_i, o)
\end{equation}

where $O$ represents the set of obstacles in the scene and $\text{dist}(q_i, o)$ calculates the closest distance between the kinematic bodies of obstacle $o$ and configuration $q_i$.

\subsubsection{Smoothness}

The smoothness of a trajectory is computed by averaging the included angle of three consecutive waypoint configurations, for all triplets of waypoints in \tj{}. The angle is computed using joint-space euclidean distance between configurations as the length of sides of the triangle.

\begin{equation}
\begin{aligned}
&\text{Smoothness} = \frac{1}{n-2} \sum_{i=1}^{n-1} \mathellipsis\\
&\left[ \pi- \text{angle}(\|q_\text{i-1}-q_\text{i}\|,\|q_\text{i}-q_\text{i+1}\|,\|q_\text{i+1}-q_\text{i-1}\|) \right]\\
\end{aligned}
\end{equation}

where the included angle is computed

\begin{equation}
\text{angle}(a,b,c) = \arccos (a^2+c^2-b^2)/2ac
\end{equation}

We compute smoothness for the joint-space trajectory \tj{} and for workspace trajectories $\xi_\text{elbow}$, $\xi_\text{wrist}$, and $\xi_\text{tip}$.

\subsubsection{Maximum Acceleration}

For a joint-space trajectory \tj{} consisting of waypoints, the maximum acceleration is computed by finding the accelerations at the knot points of splines fit to each joint's trajectory. The maximum over waypoints of the norm of these accelerations is the feature

\begin{equation}
\text{Max Acceleration} = \max_{i={0,\mathellipsis,n}} {\ddot{q}_i}^T\ddot{q}_i
\end{equation}

We compute maximum acceleration for the joint-space trajectory \tj{} and for workspace trajectories $\xi_\text{elbow}$, $\xi_\text{wrist}$, and $\xi_\text{tip}$.

\subsubsection{Maximum Radius of Curvature}

Curvature at a given waypoint is computed by first fitting the work-space trajectory with splines for each coordinate and computing from the higher order derivatives

\begin{equation}
R_i = \frac{\|\dot{q}_i\|^3}{\|\dot{q}_i \times \ddot{q}_i\|}
\end{equation}

where velocity $\dot{q}_i$ and acceleration $\ddot{q}_i$ are computed at the waypoint $i$ from differentiating the interpolating spline of the work-space trajectory. Alternatively, the higher order derviatives can be computed using finite differencing methods.

We compute maximum curvature for only the workspace trajectories $\xi_\text{elbow}$, $\xi_\text{wrist}$, and $\xi_\text{tip}$.

\subsection{Multi-Trajectory Features}
\label{subsec:multi_traj_feat}

We compared the trajectories to nominal end-effector trajectories that were created using a breadth-first search in a 3D voxel approximation of the planning problem. 

The planning scene is discretized, and voxels are marked as occupied or empty if any part of the voxel is considered in collision with the underlying planning scene. 

The start and goal voxel is simply the $(x,y,z)$ of the end-effector tool-frame. The free voxels then make up our vertices $V_\text{grid}$ for our graph.

The edges $E_\text{grid}$ used in this search are the 26-connected grid of adjacent neighboring voxels. For example, some valid adjacent voxels can be computed by adding $(\Delta x,\Delta y,\Delta z)$ to the current coordinates, where $\Delta x= \Delta y= \Delta z= \{\pm1,0\}$. An edge only exists in this graph if the ending voxel is collision.

The order the neighboring voxels are generated by the breadth-first search is done such that neighboring voxels that share \emph{faces} are pushed onto the queue before those that share an \emph{edge}, which are then added before those that share a \emph{corner} with the generating state. This lets us use a simple BFS to search the graph with unit cost edges.

Using the graph $G=(V_\text{grid}, E_\text{grid})$, we perform breadth-first search to get a collision free path from $V_\text{start}$ to $V_\text{end}$. The resulting path is given a nominal timing and we refer to it as $\xi_{\text{BFS}}$. 

We compute comparison features between $\xi_{\text{BFS}}$ and three other workspace trajectories that are computed from the forward kinematic map of the joint-space trajectory for various links in the kinematic chain, which are the elbow ($\xi_\text{elbow}$), wrist ($\xi_\text{wrist}$) and finger-tip ($\xi_\text{tip}$).

We compared them by computing the the Hausdorff distances~\cite{dubuisson1994modified}, and Dynamic Time Warping~\cite{senin2008dynamic} costs between $\xi_{\text{BFS}}$ and each of the other three.

\subsubsection{Hausdorff Distance}

The Hausdorff distance $H_\text{AB}$ between trajectory $\xi_\text{A}$ and trajectory $\xi_\text{B}$ can be computed as follows:
\begin{equation}
\begin{aligned}
H_\text{AB} &= \max (h_{\text{AB}}, h_{\text{BA}}) \\
h_{\text{AB}} &= \max_{q_\text{A} \in \xi_\text{A}} \min_{q_\text{B} \in \xi_\text{B}} \text{d}(q_\text{A}, q_\text{B})\\
h_{\text{BA}} &= \max_{q_\text{B} \in \xi_\text{B}} \min_{q_\text{A} \in \xi_\text{A}} \text{d}(q_\text{B}, q_\text{A})\\
\end{aligned}
\end{equation}

where $q_\text{A}$ is a configuration (or in this case an end effector position) at the waypoint in trajectory \tj{A} and $\text{d}(q_\text{i}, q_\text{j})$ is the euclidean distance between the trajectory waypoints.

In addition to this Hausdorff distance we also use the Interpolation-based Modified Hausdorff distance~\cite{dubuisson1994modified}~\cite{chen2013dynamic}, which is defined as:

\begin{equation}
\text{imh}_\text{AB} = \frac{1}{n_A} \sum_{q_\text{A} \in \xi_\text{A}} \min_{\overline{q_\text{B,i}} \in \xi_\text{B}} \text{d}(q_\text{A}, \overline{q_\text{B,i}})
\end{equation}

where $n(\xi)$ is the number of waypoints in the trajectory, $\overline{q_\text{B,i}}$ is the i-th segment in \tj{B}, and $\text{d}(q, \overline{q})$ is the shortest distance between the point and the line segment. We calculate this distance only one way, for $(\tj{elbow},\tj{BFS})$, $(\tj{wrist},\tj{BFS})$. and $(\tj{tip},\tj{BFS})$.

\subsubsection{Dynamic Time Warping}

Dynamic Time Warping was previously used in a wide varity of applications ranging from speech recognition, gesture recognition, handwriting matching, and can be applied here to compare two different trajectories~\cite{senin2008dynamic}\cite{chen2013dynamic}. It provides a way to compute a distance despite differences in timing of the trajectories as well.

DTW computes a mapping of a subset of the waypoints in $\xi_\text{A}$ to a subset of the waypoints in $\xi_\text{B}$ which constitutes the warping path, or

\begin{equation}
\xi_\text{DTW} = \{ (0, 0), (a_i, b_j), \mathellipsis ,(n_A, n_B) \}
\end{equation}

where $n_A = |\tj{A}|$ and $n_B = |\tj{B}|$ which are the number of waypoints in the trajectory.

The path is constrained to map the first waypoints and last waypoints together, which makes up a boundary condition. Finally, the warping path is continuous and monotone such that each coordinate of the waypoint in the warping path is between 0 and 1 of the coordinate of the preceding waypoint in the path, or

\begin{equation}
\forall_{(a_i,b_i) \in \xi_\text{DTW}} 
  \begin{cases}
      0 \leq a_{i} - a_{i-1} \leq 1 \\
      0 \leq b_{i} - b_{i-1} \leq 1 \\
  \end{cases}
\end{equation}

Computing this warping path cost is done by framing it as a dynamic programming problem where the cumulative DTW cost of a cell is done on a $n_B+1 \times n_B+1$ array and initialized such that

\begin{equation}
\begin{aligned}
\text{DTW}[0,0] &= 0 \\
\forall_{i=\{1,\mathellipsis,n_A\}} \text{DTW}[i,0] &= \inf\\
\forall_{j=\{1,\mathellipsis,n_B\}} \text{DTW}[0,j] &= \inf\\
\end{aligned}
\end{equation}

and the algorithm iterates over $i=\{1,\mathellipsis,|\tj{A}|\}$ and $j=\{1,\mathellipsis,|\tj{B}|\}$ and updates the the cell at an index $(i,j)$ with the rule

\begin{equation}
\text{DTW}[i,j] = \text{d}_{i,j} + \min 
  \begin{cases}
    \text{DTW}[i-1,j] \\
    \text{DTW}[i,j-1] \\
    \text{DTW}[i-1,j-1] ) \\
  \end{cases}
\end{equation}

where $\text{d}_{i,j}$ is the euclidean distance between waypoint $i$-th waypoint of \tj{A} and $j$-th waypoint of \tj{B}. After computing this array, $\text{DTW}[n_A, n_B]$ gives the cost or distance between \tj{A} and \tj{B}.

\todo Write about:
\begin{itemize}
\item get example trajectories (without elbow path)
\item get example snapshots high-low values of features
\end{itemize}

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{ACKNOWLEDGMENT}

The preferred spelling of the word �acknowledgment� in America is without an �e� after the �g�. Avoid the stilted expression, �One of us (R. B. G.) thanks . . .�  Instead, try �R. B. G. thanks�. Put sponsor acknowledgments in the unnumbered footnote on the first page.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliography{IEEEabrv,max,arjun}
\bibliographystyle{IEEEtran}



\end{document}
